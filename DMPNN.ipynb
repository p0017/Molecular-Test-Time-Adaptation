{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7ec02f-bc61-4c89-987d-b3025b2a474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.nn import global_add_pool\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb419790-ae4f-478b-8ecf-843e1aa4375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom):\n",
    "    features = onek_encoding_unk(atom.GetSymbol(), ['B','Be','Br','C','Cl','F','I','N','Nb','O','P','S','Se','Si','V','W']) + \\\n",
    "        onek_encoding_unk(atom.GetTotalDegree(), [0, 1, 2, 3, 4, 5]) + \\\n",
    "        onek_encoding_unk(atom.GetFormalCharge(), [-1, -2, 1, 2, 0]) + \\\n",
    "        onek_encoding_unk(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4]) + \\\n",
    "        onek_encoding_unk(int(atom.GetHybridization()),[Chem.rdchem.HybridizationType.SP,\n",
    "                                                        Chem.rdchem.HybridizationType.SP2,\n",
    "                                                        Chem.rdchem.HybridizationType.SP3,\n",
    "                                                        Chem.rdchem.HybridizationType.SP3D,\n",
    "                                                        Chem.rdchem.HybridizationType.SP3D2\n",
    "                                                        ]) + \\\n",
    "        [1 if atom.GetIsAromatic() else 0] + \\\n",
    "        [atom.GetMass() * 0.01]\n",
    "    return features\n",
    "\n",
    "def bond_features(bond):\n",
    "    bond_fdim = 7\n",
    "\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (bond_fdim - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            (bond.GetIsConjugated() if bt is not None else 0),\n",
    "            (bond.IsInRing() if bt is not None else 0)\n",
    "        ]\n",
    "    return fbond\n",
    "\n",
    "def onek_encoding_unk(value, choices):\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "    return encoding\n",
    "\n",
    "def make_mol(smi):\n",
    "    return Chem.MolFromSmiles(smi)\n",
    "\n",
    "class MolGraph:\n",
    "    def __init__(self, smiles):\n",
    "        self.smiles = smiles\n",
    "        self.f_atoms = []\n",
    "        self.f_bonds = []\n",
    "        self.edge_index = []\n",
    "\n",
    "        mol = make_mol(self.smiles)\n",
    "        n_atoms=mol.GetNumAtoms()\n",
    "\n",
    "        for a1 in range(n_atoms):\n",
    "            f_atom = atom_features(mol.GetAtomWithIdx(a1))\n",
    "            self.f_atoms.append(f_atom)\n",
    "\n",
    "            for a2 in range(a1 + 1, n_atoms):\n",
    "                bond = mol.GetBondBetweenAtoms(a1, a2)\n",
    "                if bond is None:\n",
    "                    continue\n",
    "                f_bond = bond_features(bond)\n",
    "                self.f_bonds.append(f_bond)\n",
    "                self.f_bonds.append(f_bond)\n",
    "                self.edge_index.extend([(a1, a2), (a2, a1)])\n",
    "\n",
    "class ChemDataset(Dataset):\n",
    "    def __init__(self, smiles, labels):\n",
    "        super(ChemDataset, self).__init__()\n",
    "        self.smiles = smiles\n",
    "        self.labels = labels\n",
    "        self.cache = {}\n",
    "\n",
    "    def process_key(self, key):\n",
    "        smi = self.smiles[key]\n",
    "        if smi in self.cache.keys():\n",
    "            mol = self.cache[smi]\n",
    "        else:\n",
    "            molgraph = MolGraph(smi)\n",
    "            mol = self.molgraph2data(molgraph, key)\n",
    "            self.cache[smi] = mol\n",
    "        return mol\n",
    "\n",
    "    def molgraph2data(self, molgraph, key):\n",
    "        data = tg.data.Data()\n",
    "        data.x = torch.tensor(molgraph.f_atoms, dtype=torch.float)\n",
    "        data.edge_index = torch.tensor(molgraph.edge_index, dtype=torch.long).t().contiguous()\n",
    "        data.edge_attr = torch.tensor(molgraph.f_bonds, dtype=torch.float)\n",
    "        data.y = torch.tensor([self.labels[key]], dtype=torch.float)\n",
    "        data.smiles = self.smiles[key]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get(self,key):\n",
    "        return self.process_key(key)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.smiles)\n",
    "        \n",
    "def construct_loader(data_df, smi_column, target_column, shuffle=True, batch_size=50):    \n",
    "    smiles = data_df[smi_column].values\n",
    "    labels = data_df[target_column].values.astype(np.float32)  \n",
    "    \n",
    "    dataset = ChemDataset(smiles, labels)\n",
    "    loader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            pin_memory=True\n",
    "                       )\n",
    "    return loader\n",
    "    \n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.depth = 3\n",
    "        self.hidden_size = 300\n",
    "        self.dropout = 0.02\n",
    "\n",
    "        self.edge_init = nn.Linear(num_node_features + num_edge_features, self.hidden_size)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(self.depth):\n",
    "            self.convs.append(DMPNNConv(self.hidden_size))\n",
    "        self.edge_to_node = nn.Linear(num_node_features + self.hidden_size, self.hidden_size)\n",
    "        self.pool = global_add_pool\n",
    "        self.ffn1 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.ffn2 = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # initial edge features\n",
    "        row, col = edge_index\n",
    "        h_0 = F.relu(self.edge_init(torch.cat([x[row], edge_attr], dim=1)))\n",
    "        h = h_0\n",
    "\n",
    "        # convolutions\n",
    "        for l in range(self.depth):\n",
    "            _, h = self.convs[l](edge_index, h)\n",
    "            h += h_0\n",
    "            h = F.dropout(F.relu(h), self.dropout, training=self.training)\n",
    "\n",
    "        # dmpnn edge -> node aggregation\n",
    "        s, _ = self.convs[l](edge_index, h) #only use for summing\n",
    "        try:\n",
    "            q  = torch.cat([x,s], dim=1)\n",
    "        except:\n",
    "            print(data)\n",
    "            print(data.smiles)\n",
    "            print(data.x)\n",
    "            q  = torch.cat([x,s], dim=1)\n",
    "        h = F.relu(self.edge_to_node(q))\n",
    "\n",
    "        return self.ffn2(F.dropout(F.relu(self.ffn1(self.pool(h, batch))))).squeeze(-1)\n",
    "\n",
    "class DMPNNConv(MessagePassing):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DMPNNConv, self).__init__(aggr='add')\n",
    "        self.lin = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, edge_index, edge_attr):\n",
    "        row, col = edge_index\n",
    "        a_message = self.propagate(edge_index, x=None, edge_attr=edge_attr)\n",
    "        rev_message = torch.flip(edge_attr.view(edge_attr.size(0) // 2, 2, -1), dims=[1]).view(edge_attr.size(0), -1)\n",
    "\n",
    "        return a_message, self.lin(a_message[row] - rev_message)\n",
    "\n",
    "    def message(self, edge_attr):\n",
    "        return edge_attr\n",
    "\n",
    "class Standardizer:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, x, rev=False):\n",
    "        if rev:\n",
    "            return (x * self.std) + self.mean\n",
    "        return (x - self.mean) / self.std\n",
    "\n",
    "def train_epoch(model, loader, optimizer, loss, stdzer):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(data)\n",
    "        result = loss(out, stdzer(data.y))\n",
    "        result.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss_all += loss(stdzer(out, rev=True), data.y)\n",
    "\n",
    "    return math.sqrt(loss_all / len(loader.dataset))\n",
    "\n",
    "def pred(model, loader, loss, stdzer):\n",
    "    model.eval()\n",
    "\n",
    "    preds, ys = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data)\n",
    "            pred = stdzer(out, rev=True)\n",
    "            preds.extend(pred.cpu().detach().tolist())\n",
    "\n",
    "    return preds\n",
    "\n",
    "def train():\n",
    "    torch.manual_seed(0)\n",
    "    data_df = pd.read_csv(\"AqSolDBc.csv\")\n",
    "    #Drop single atoms    \n",
    "    idx_single = [i for i,s in enumerate(data_df['SmilesCurated']) if Chem.MolFromSmiles(s).GetNumAtoms()==1 or '.' in s]\n",
    "    data_df = data_df.drop(idx_single)\n",
    "    if len(idx_single)>0:\n",
    "        print(\"Removing\", idx_single)\n",
    "\n",
    "        \n",
    "    test_df = pd.read_csv(\"OChemUnseen.csv\")\n",
    "    #Drop single atoms    \n",
    "    idx_single = [i for i,s in enumerate(test_df['SMILES']) if Chem.MolFromSmiles(s).GetNumAtoms()==1 or '.' in s]\n",
    "    test_df = test_df.drop(idx_single)\n",
    "    if len(idx_single)>0:\n",
    "        print(\"Removing\", idx_single)\n",
    "\n",
    "        \n",
    "    train_df, val_df = train_test_split(data_df, test_size=0.2, random_state=0)\n",
    "    train_loader = construct_loader(train_df, 'SmilesCurated', 'ExperimentalLogS', shuffle=True)\n",
    "    val_loader = construct_loader(val_df, 'SmilesCurated', 'ExperimentalLogS', shuffle=False)\n",
    "    test_loader = construct_loader(test_df, 'SMILES', 'LogS', shuffle=False)\n",
    "    mean = np.mean(train_loader.dataset.labels)\n",
    "    std = np.std(train_loader.dataset.labels)\n",
    "    stdzer = Standardizer(mean, std)\n",
    "\n",
    "    model = GNN(train_loader.dataset.num_node_features, train_loader.dataset.num_edge_features)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss = nn.MSELoss(reduction='sum')\n",
    "    print(model)\n",
    "    best_model = model\n",
    "    best_val_loss = 1000000\n",
    "    for epoch in range(0, 30):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, loss, stdzer)\n",
    "        preds = pred(model, val_loader, loss, stdzer)\n",
    "        val_loss = root_mean_squared_error(preds,val_loader.dataset.labels)\n",
    "        print(\"Epoch\",epoch,\"  Train RMSE\", train_loss,\"   Val RMSE\", val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_model = deepcopy(model)\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "    preds = pred(best_model, test_loader, loss, stdzer)\n",
    "    print(\"Test RMSE\", root_mean_squared_error(preds,test_loader.dataset.labels))\n",
    "    print(\"Test MAE\", mean_absolute_error(preds,test_loader.dataset.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28a5c5d5-2466-4aa0-87c9-1074170fb57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing [1263, 1444, 3605, 3702]\n",
      "Removing [471, 503, 589, 591, 592, 593, 594, 610, 613, 641, 643, 647, 649, 652, 653, 654, 656, 658, 667, 677, 682, 694, 745, 760, 764, 770, 774, 778, 808, 810, 812, 814, 870, 903, 970, 999]\n",
      "GNN(\n",
      "  (edge_init): Linear(in_features=51, out_features=300, bias=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-2): 3 x DMPNNConv()\n",
      "  )\n",
      "  (edge_to_node): Linear(in_features=344, out_features=300, bias=True)\n",
      "  (ffn1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (ffn2): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 0   Train RMSE 2.2815077126611096    Val RMSE 1.5524550342218395\n",
      "Epoch 1   Train RMSE 1.4414327975673906    Val RMSE 1.2493980958363329\n",
      "Epoch 2   Train RMSE 1.2431019709828859    Val RMSE 1.2205187176712469\n",
      "Epoch 3   Train RMSE 1.1810754354353674    Val RMSE 1.0772295766859485\n",
      "Epoch 4   Train RMSE 1.1237264948541177    Val RMSE 1.100075920607069\n",
      "Epoch 5   Train RMSE 1.072391968112308    Val RMSE 1.0304469206271332\n",
      "Epoch 6   Train RMSE 1.0550970342043968    Val RMSE 1.0758545731565052\n",
      "Epoch 7   Train RMSE 1.0535314369924536    Val RMSE 1.0125628269862612\n",
      "Epoch 8   Train RMSE 1.0132726570417978    Val RMSE 0.9800908056383545\n",
      "Epoch 9   Train RMSE 0.9896234738423793    Val RMSE 0.9867994937898457\n",
      "Epoch 10   Train RMSE 0.9687069914099949    Val RMSE 0.9720098378862004\n",
      "Epoch 11   Train RMSE 0.9393898353750368    Val RMSE 1.0567089391402458\n",
      "Epoch 12   Train RMSE 0.9545456976085205    Val RMSE 0.9682557488462269\n",
      "Epoch 13   Train RMSE 0.9324237403163782    Val RMSE 1.004617052331811\n",
      "Epoch 14   Train RMSE 0.9173777199421703    Val RMSE 0.9828717313051064\n",
      "Epoch 15   Train RMSE 0.9010494246543934    Val RMSE 0.9538295196557254\n",
      "Epoch 16   Train RMSE 0.8808320373217655    Val RMSE 1.0208452758668438\n",
      "Epoch 17   Train RMSE 0.8754940341264732    Val RMSE 0.9530630501242281\n",
      "Epoch 18   Train RMSE 0.8546998561823751    Val RMSE 0.9434617410498868\n",
      "Epoch 19   Train RMSE 0.8510542236360479    Val RMSE 0.977562613013475\n",
      "Epoch 20   Train RMSE 0.8473714886345135    Val RMSE 0.978582975961625\n",
      "Epoch 21   Train RMSE 0.8254438578982592    Val RMSE 0.9400571691778074\n",
      "Epoch 22   Train RMSE 0.8281791957179507    Val RMSE 0.9801226267169245\n",
      "Epoch 23   Train RMSE 0.8180257622525667    Val RMSE 0.9350363529744469\n",
      "Epoch 24   Train RMSE 0.8201268667261746    Val RMSE 0.9580124374379819\n",
      "Epoch 25   Train RMSE 0.789776733755025    Val RMSE 0.9255149748444859\n",
      "Epoch 26   Train RMSE 0.7778428358918835    Val RMSE 0.9884690746994161\n",
      "Epoch 27   Train RMSE 0.7620444750659946    Val RMSE 0.9127242450594167\n",
      "Epoch 28   Train RMSE 0.7525481408901009    Val RMSE 0.9436076805395199\n",
      "Epoch 29   Train RMSE 0.7514850298950756    Val RMSE 1.0118743716940266\n",
      "Test RMSE 1.3319730980653688\n",
      "Test MAE 0.9478033764609483\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b73f6c66-def3-47ba-bc90-c8e9fe09aeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8046"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd326a-a80a-418e-8a56-a04e84ec38a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
